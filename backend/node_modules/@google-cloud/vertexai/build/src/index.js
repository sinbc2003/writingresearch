"use strict";
/**
 * @license
 * Copyright 2023 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.GenerativeModel = exports.ChatSession = exports.VertexAI_Preview = exports.VertexAI = void 0;
/* tslint:disable */
const google_auth_library_1 = require("google-auth-library");
const process_stream_1 = require("./process_stream");
const errors_1 = require("./types/errors");
const util_1 = require("./util");
__exportStar(require("./types"), exports);
/**
 * Base class for authenticating to Vertex, creates the preview namespace.
 */
class VertexAI {
    /**
     * @constructor
     * @param {VertexInit} init - assign authentication related information,
     *     including project and location string, to instantiate a Vertex AI
     * client.
     */
    constructor(init) {
        /**
         * preview property is used to access any SDK methods available in public
         * preview, currently all functionality.
         */
        this.preview = new VertexAI_Preview(init.project, init.location, init.apiEndpoint, init.googleAuthOptions);
    }
}
exports.VertexAI = VertexAI;
/**
 * VertexAI class internal implementation for authentication.
 */
class VertexAI_Preview {
    /**
     * @constructor
     * @param {string} - project The Google Cloud project to use for the request
     * @param {string} - location The Google Cloud project location to use for the request
     * @param {string} - [apiEndpoint] The base Vertex AI endpoint to use for the request. If
     *        not provided, the default regionalized endpoint
     *        (i.e. us-central1-aiplatform.googleapis.com) will be used.
     * @param {GoogleAuthOptions} - [googleAuthOptions] The Authentication options provided by google-auth-library.
     *        Complete list of authentication options is documented in the GoogleAuthOptions interface:
     *        https://github.com/googleapis/google-auth-library-nodejs/blob/main/src/auth/googleauth.ts
     */
    constructor(project, location, apiEndpoint, googleAuthOptions) {
        this.project = project;
        this.location = location;
        this.apiEndpoint = apiEndpoint;
        this.googleAuthOptions = googleAuthOptions;
        const opts = this.validateGoogleAuthOptions(project, googleAuthOptions);
        this.project = project;
        this.location = location;
        this.apiEndpoint = apiEndpoint;
        this.googleAuth = new google_auth_library_1.GoogleAuth(opts);
    }
    /**
     * @param {ModelParams} modelParams - {@link ModelParams} Parameters to specify the generative model.
     * @return {GenerativeModel} Instance of the GenerativeModel class. {@link GenerativeModel}
     */
    getGenerativeModel(modelParams) {
        const getGenerativeModelParams = {
            model: modelParams.model,
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            apiEndpoint: this.apiEndpoint,
            safety_settings: modelParams.safety_settings,
            tools: modelParams.tools,
        };
        if (modelParams.generation_config) {
            getGenerativeModelParams.generation_config = validateGenerationConfig(modelParams.generation_config);
        }
        return new GenerativeModel(getGenerativeModelParams);
    }
    validateGoogleAuthOptions(project, googleAuthOptions) {
        let opts;
        const requiredScope = 'https://www.googleapis.com/auth/cloud-platform';
        if (!googleAuthOptions) {
            opts = {
                scopes: requiredScope,
            };
            return opts;
        }
        if (googleAuthOptions.projectId &&
            googleAuthOptions.projectId !== project) {
            throw new Error(`inconsistent project ID values. argument project got value ${project} but googleAuthOptions.projectId got value ${googleAuthOptions.projectId}`);
        }
        opts = googleAuthOptions;
        if (!opts.scopes) {
            opts.scopes = requiredScope;
            return opts;
        }
        if ((typeof opts.scopes === 'string' && opts.scopes !== requiredScope) ||
            (Array.isArray(opts.scopes) && opts.scopes.indexOf(requiredScope) < 0)) {
            throw new errors_1.GoogleAuthError(`input GoogleAuthOptions.scopes ${opts.scopes} doesn't contain required scope ${requiredScope}, please include ${requiredScope} into GoogleAuthOptions.scopes or leave GoogleAuthOptions.scopes undefined`);
        }
        return opts;
    }
}
exports.VertexAI_Preview = VertexAI_Preview;
/**
 * Chat session to make multi-turn send message request.
 * `sendMessage` method makes async call to get response of a chat message.
 * `sendMessageStream` method makes async call to stream response of a chat message.
 */
class ChatSession {
    get history() {
        return this.historyInternal;
    }
    /**
     * @constructor
     * @param {StartChatSessionRequest} request - {@link StartChatSessionRequest}
     */
    constructor(request) {
        var _a;
        this._send_stream_promise = Promise.resolve();
        this.project = request.project;
        this.location = request.location;
        this._model_instance = request._model_instance;
        this.historyInternal = (_a = request.history) !== null && _a !== void 0 ? _a : [];
        this.generation_config = request.generation_config;
        this.safety_settings = request.safety_settings;
        this.tools = request.tools;
    }
    /**
     * Make an sync call to send message.
     * @param {string | Array<string | Part>} request - send message request. {@link Part}
     * @return {Promise<GenerateContentResult>} Promise of {@link GenerateContentResult}
     */
    async sendMessage(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentrequest = {
            contents: this.historyInternal.concat(newContent),
            safety_settings: this.safety_settings,
            generation_config: this.generation_config,
            tools: this.tools,
        };
        const generateContentResult = await this._model_instance
            .generateContent(generateContentrequest)
            .catch(e => {
            throw e;
        });
        const generateContentResponse = await generateContentResult.response;
        // Only push the latest message to history if the response returned a result
        if (generateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromAssistant = generateContentResponse.candidates[0].content;
            if (!contentFromAssistant.role) {
                contentFromAssistant.role = util_1.constants.MODEL_ROLE;
            }
            this.historyInternal.push(contentFromAssistant);
        }
        else {
            // TODO: handle promptFeedback in the response
            throw new Error('Did not get a candidate from the model');
        }
        return Promise.resolve({ response: generateContentResponse });
    }
    async appendHistory(streamGenerateContentResultPromise, newContent) {
        const streamGenerateContentResult = await streamGenerateContentResultPromise;
        const streamGenerateContentResponse = await streamGenerateContentResult.response;
        // Only push the latest message to history if the response returned a result
        if (streamGenerateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromAssistant = streamGenerateContentResponse.candidates[0].content;
            if (!contentFromAssistant.role) {
                contentFromAssistant.role = util_1.constants.MODEL_ROLE;
            }
            this.historyInternal.push(contentFromAssistant);
        }
        else {
            // TODO: handle promptFeedback in the response
            throw new Error('Did not get a candidate from the model');
        }
    }
    /**
     * Make an async call to stream send message. Response will be returned in stream.
     * @param {string | Array<string | Part>} request - send message request. {@link Part}
     * @return {Promise<StreamGenerateContentResult>} Promise of {@link StreamGenerateContentResult}
     */
    async sendMessageStream(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentrequest = {
            contents: this.historyInternal.concat(newContent),
            safety_settings: this.safety_settings,
            generation_config: this.generation_config,
            tools: this.tools,
        };
        const streamGenerateContentResultPromise = this._model_instance
            .generateContentStream(generateContentrequest)
            .catch(e => {
            throw e;
        });
        this._send_stream_promise = this.appendHistory(streamGenerateContentResultPromise, newContent).catch(e => {
            throw new errors_1.GoogleGenerativeAIError('exception appending chat history', e);
        });
        return streamGenerateContentResultPromise;
    }
}
exports.ChatSession = ChatSession;
/**
 * Base class for generative models.
 * NOTE: this class should not be instantiated directly. Use
 * `vertexai.preview.getGenerativeModel()` instead.
 */
class GenerativeModel {
    /**
     * @constructor
     * @param {GetGenerativeModelParams} getGenerativeModelParams - {@link GetGenerativeModelParams}
     */
    constructor(getGenerativeModelParams) {
        this.project = getGenerativeModelParams.project;
        this.location = getGenerativeModelParams.location;
        this.apiEndpoint = getGenerativeModelParams.apiEndpoint;
        this.googleAuth = getGenerativeModelParams.googleAuth;
        this.model = getGenerativeModelParams.model;
        this.generation_config = getGenerativeModelParams.generation_config;
        this.safety_settings = getGenerativeModelParams.safety_settings;
        this.tools = getGenerativeModelParams.tools;
        if (this.model.startsWith('models/')) {
            this.publisherModelEndpoint = `publishers/google/${this.model}`;
        }
        else {
            this.publisherModelEndpoint = `publishers/google/models/${this.model}`;
        }
    }
    /**
     * Get access token from GoogleAuth. Throws GoogleAuthError when fails.
     * @return {Promise<any>} Promise of token
     */
    get token() {
        const credential_error_message = '\nUnable to authenticate your request\
        \nDepending on your run time environment, you can get authentication by\
        \n- if in local instance or cloud shell: `!gcloud auth login`\
        \n- if in Colab:\
        \n    -`from google.colab import auth`\
        \n    -`auth.authenticate_user()`\
        \n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication';
        const tokenPromise = this.googleAuth.getAccessToken().catch(e => {
            throw new errors_1.GoogleAuthError(credential_error_message, e);
        });
        return tokenPromise;
    }
    /**
     * Make a async call to generate content.
     * @param request A GenerateContentRequest object with the request contents.
     * @return The GenerateContentResponse object with the response candidates.
     */
    async generateContent(request) {
        var _a, _b, _c;
        request = formatContentRequest(request, this.generation_config, this.safety_settings);
        validateGenerateContentRequest(request);
        if (request.generation_config) {
            request.generation_config = validateGenerationConfig(request.generation_config);
        }
        const generateContentRequest = {
            contents: request.contents,
            generation_config: (_a = request.generation_config) !== null && _a !== void 0 ? _a : this.generation_config,
            safety_settings: (_b = request.safety_settings) !== null && _b !== void 0 ? _b : this.safety_settings,
            tools: (_c = request.tools) !== null && _c !== void 0 ? _c : [],
        };
        const response = await (0, util_1.postRequest)({
            region: this.location,
            project: this.project,
            resourcePath: this.publisherModelEndpoint,
            resourceMethod: util_1.constants.GENERATE_CONTENT_METHOD,
            token: await this.token,
            data: generateContentRequest,
            apiEndpoint: this.apiEndpoint,
        }).catch(e => {
            throw new errors_1.GoogleGenerativeAIError('exception posting request', e);
        });
        throwErrorIfNotOK(response);
        const result = (0, process_stream_1.processNonStream)(response);
        return Promise.resolve(result);
    }
    /**
     * Make an async stream request to generate content. The response will be returned in stream.
     * @param {GenerateContentRequest} request - {@link GenerateContentRequest}
     * @return {Promise<StreamGenerateContentResult>} Promise of {@link StreamGenerateContentResult}
     */
    async generateContentStream(request) {
        var _a, _b, _c;
        request = formatContentRequest(request, this.generation_config, this.safety_settings);
        validateGenerateContentRequest(request);
        if (request.generation_config) {
            request.generation_config = validateGenerationConfig(request.generation_config);
        }
        const generateContentRequest = {
            contents: request.contents,
            generation_config: (_a = request.generation_config) !== null && _a !== void 0 ? _a : this.generation_config,
            safety_settings: (_b = request.safety_settings) !== null && _b !== void 0 ? _b : this.safety_settings,
            tools: (_c = request.tools) !== null && _c !== void 0 ? _c : [],
        };
        const response = await (0, util_1.postRequest)({
            region: this.location,
            project: this.project,
            resourcePath: this.publisherModelEndpoint,
            resourceMethod: util_1.constants.STREAMING_GENERATE_CONTENT_METHOD,
            token: await this.token,
            data: generateContentRequest,
            apiEndpoint: this.apiEndpoint,
        }).catch(e => {
            throw new errors_1.GoogleGenerativeAIError('exception posting request', e);
        });
        throwErrorIfNotOK(response);
        const streamResult = (0, process_stream_1.processStream)(response);
        return Promise.resolve(streamResult);
    }
    /**
     * Make a async request to count tokens.
     * @param request A CountTokensRequest object with the request contents.
     * @return The CountTokensResponse object with the token count.
     */
    async countTokens(request) {
        const response = await (0, util_1.postRequest)({
            region: this.location,
            project: this.project,
            resourcePath: this.publisherModelEndpoint,
            resourceMethod: 'countTokens',
            token: await this.token,
            data: request,
            apiEndpoint: this.apiEndpoint,
        }).catch(e => {
            throw new errors_1.GoogleGenerativeAIError('exception posting request', e);
        });
        throwErrorIfNotOK(response);
        return (0, process_stream_1.processCountTokenResponse)(response);
    }
    /**
     * Instantiate a ChatSession.
     * This method doesn't make any call to remote endpoint.
     * Any call to remote endpoint is implemented in ChatSession class @see ChatSession
     * @param{StartChatParams} [request] - {@link StartChatParams}
     * @return {ChatSession} {@link ChatSession}
     */
    startChat(request) {
        var _a, _b, _c;
        const startChatRequest = {
            project: this.project,
            location: this.location,
            _model_instance: this,
        };
        if (request) {
            startChatRequest.history = request.history;
            startChatRequest.generation_config =
                (_a = request.generation_config) !== null && _a !== void 0 ? _a : this.generation_config;
            startChatRequest.safety_settings =
                (_b = request.safety_settings) !== null && _b !== void 0 ? _b : this.safety_settings;
            startChatRequest.tools = (_c = request.tools) !== null && _c !== void 0 ? _c : this.tools;
        }
        return new ChatSession(startChatRequest);
    }
}
exports.GenerativeModel = GenerativeModel;
function formulateNewContentFromSendMessageRequest(request) {
    let newParts = [];
    if (typeof request === 'string') {
        newParts = [{ text: request }];
    }
    else if (Array.isArray(request)) {
        for (const item of request) {
            if (typeof item === 'string') {
                newParts.push({ text: item });
            }
            else {
                newParts.push(item);
            }
        }
    }
    return assignRoleToPartsAndValidateSendMessageRequest(newParts);
}
/**
 * When multiple Part types (i.e. FunctionResponsePart and TextPart) are
 * passed in a single Part array, we may need to assign different roles to each
 * part. Currently only FunctionResponsePart requires a role other than 'user'.
 * @ignore
 * @param {Array<Part>} parts Array of parts to pass to the model
 * @return {Content[]} Array of content items
 */
function assignRoleToPartsAndValidateSendMessageRequest(parts) {
    const userContent = { role: util_1.constants.USER_ROLE, parts: [] };
    const functionContent = { role: util_1.constants.FUNCTION_ROLE, parts: [] };
    let hasUserContent = false;
    let hasFunctionContent = false;
    for (const part of parts) {
        if ('functionResponse' in part) {
            functionContent.parts.push(part);
            hasFunctionContent = true;
        }
        else {
            userContent.parts.push(part);
            hasUserContent = true;
        }
    }
    if (hasUserContent && hasFunctionContent) {
        throw new errors_1.ClientError('Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.');
    }
    if (!hasUserContent && !hasFunctionContent) {
        throw new errors_1.ClientError('No content is provided for sending chat message.');
    }
    if (hasUserContent) {
        return [userContent];
    }
    return [functionContent];
}
function throwErrorIfNotOK(response) {
    if (response === undefined) {
        throw new errors_1.GoogleGenerativeAIError('response is undefined');
    }
    const status = response.status;
    const statusText = response.statusText;
    const errorMessage = `got status: ${status} ${statusText}`;
    if (status >= 400 && status < 500) {
        throw new errors_1.ClientError(errorMessage);
    }
    if (!response.ok) {
        throw new errors_1.GoogleGenerativeAIError(errorMessage);
    }
}
function validateGcsInput(contents) {
    for (const content of contents) {
        for (const part of content.parts) {
            if ('file_data' in part) {
                // @ts-ignore
                const uri = part['file_data']['file_uri'];
                if (!uri.startsWith('gs://')) {
                    throw new URIError(`Found invalid Google Cloud Storage URI ${uri}, Google Cloud Storage URIs must start with gs://`);
                }
            }
        }
    }
}
function validateFunctionResponseRequest(contents) {
    const lastestContentPart = contents[contents.length - 1].parts[0];
    if (!('functionResponse' in lastestContentPart)) {
        return;
    }
    const errorMessage = 'Please ensure that function response turn comes immediately after a function call turn.';
    if (contents.length < 2) {
        throw new errors_1.ClientError(errorMessage);
    }
    const secondLastestContentPart = contents[contents.length - 2].parts[0];
    if (!('functionCall' in secondLastestContentPart)) {
        throw new errors_1.ClientError(errorMessage);
    }
}
function validateGenerateContentRequest(request) {
    validateGcsInput(request.contents);
    validateFunctionResponseRequest(request.contents);
}
function validateGenerationConfig(generation_config) {
    if ('top_k' in generation_config) {
        if (!(generation_config.top_k > 0) || !(generation_config.top_k <= 40)) {
            delete generation_config.top_k;
        }
    }
    return generation_config;
}
function formatContentRequest(request, generation_config, safety_settings) {
    if (typeof request === 'string') {
        return {
            contents: [{ role: util_1.constants.USER_ROLE, parts: [{ text: request }] }],
            generation_config: generation_config,
            safety_settings: safety_settings,
        };
    }
    else {
        return request;
    }
}
//# sourceMappingURL=index.js.map